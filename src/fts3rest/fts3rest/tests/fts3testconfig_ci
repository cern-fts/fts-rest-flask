# Running user and group
User=ci
Group=ci

# mysql only
DbType=mysql

#db username
DbUserName=ftsflask

#db password
DbPassword=asdf


#For MySQL, it has to follow the format 'host/db' (i.e. "mysql-server.example.com/fts3db")
DbConnectString=mariadb:3306/ftsflask

#Number of db connections in the pool (use even number, e.g. 2,4,6,8,etc OR 1 for a single connection)
DbThreadsNum=30

#The alias used for the FTS endpoint, will be published as such in the dashboard transfers UI http://dashb-wlcg-transfers.cern.ch/ui/
#Alias=fts3-xdc.cern.ch

#Infosys, either the fqdn:port of a BDII instance or false to disable BDII access
#Infosys=lcg-bdii.cern.ch:2170

#Query the info systems specified in the order given, e.g. glue1;glue2
InfoProviders=glue1

#List of authorized VOs, separated by ;
#Leave * to authorize any VO
AuthorizedVO=*

# site name
#SiteName=FTS-DEV-XDC

#Enable/Disable monitoring using messaging monitoring (disabled=false / enabled=true)
MonitoringMessaging=false

# Profiling interval in seconds. If set to 0, it will be disabled
Profiling=0

# Log directories
TransferLogDirectory=/var/log/fts3/transfers
ServerLogDirectory=/var/log/fts3

# Log level. Enables logging for messages of level >= than configured
# Possible values are
#   TRACE (every detail), DEBUG (internal behaviour), INFO (normal behaviour),
#   NOTICE (final states), WARNING (things worth checking), ERR (internal FTS3 errors, as database connectivity),
#   CRIT (fatal errors, as segmentation fault)
# It is recommended to use DEBUG or INFO
LogLevel=DEBUG

# Check for fts_url_copy processes that do not give their progress back
# CheckStalledTransfers = true
# Stalled timeout, in seconds
# CheckStalledTimeout = 900
CheckStalledTimeout = 900

# Minimum required free RAM (in MB) for FTS3 to work normally
# If the amount of free RAM goes below the limit, FTS3 will enter auto-drain mode
# This is intended to protect against system resource exhaustion
# MinRequiredFreeRAM = 50
MinRequiredFreeRAM = 50

# Maximum number of url copy processes that the node can run
# The RAM limitation may not take into account other node limitations (i.e. IO)
# or, depending on the swapping policy, may not even prevent overloads if the kernel
# starts swapping before the free RAM decreases until it reaches the value of MinRequiredFreeRAM
# 0 disables the check.
# The default is 400.
# MaxUrlCopyProcesses = 400
MaxUrlCopyProcesses = 400

# Parameters for Bring Online
# Maximum bulk size.
# If the size is too large, it will take more resources (memory and CPU) to generate the requests and
# parse the responses. Some servers may reject the requests if they are too big.
# If it is too small, performance will be reduced.
# Keep it to a sensible size (between 100 and 1k)
# StagingBulkSize=400
# Maximum number of concurrent requests. This gives a maximum of files sent to the storage system
# (StagingBulkSize*StagingConcurrentRequests). The larger the number, the more requests will FTS need to keep track of.
# StagingConcurrentRequests=500
# Seconds to wait before submitting a bulk request, so FTS can accumulate more files per bulk.
# Note that the resolution is 60 seconds.
# StagingWaitingFactor=300
# Retry this number of times if a staging poll fails with ECOMM
# StagingPollRetries=3

# In seconds, interval between heartbeats
# HeartBeatInterval=60
# I seconds, after this interval a host is considered down
# HeartBeatGraceInterval=120

# Seconds between optimizer runs
# OptimizerInterval = 60
# After this time without optimizer updates, force a run
# OptimizerSteadyInterval = 300
# Maximum number of streams per file
# OptimizerMaxStreams = 16

# EMA Alpha factor to reduce the influence of fluctuations
# OptimizerEMAAlpha = 0.1
# Increase step size when the optimizer considers the performance is good
# OptimizerIncreaseStep = 1
# Increase step size when the optimizer considers the performance is good, and set to aggressive or normal
# OptimizerAggressiveIncreaseStep = 2
# Decrease step size when the optimizer considers the performance is bad
# OptimizerDecreaseStep = 1


# Set the bulk size, in number of jobs, used for cleaning the old records
#CleanBulkSize=5000
# In days. Entries older than this will be purged.
#CleanInterval=7

## The higher the values for the following parameters,
## the higher the latency for some operations (as cancelations),
## but can also reduce the system and/or database load

# In seconds, how often to purge the messaging directory
#PurgeMessagingDirectoryInterval = 600
# In seconds, how often to run sanity checks
#CheckSanityStateInterval = 3600
# In seconds, how often to check for canceled transfers
#CancelCheckInterval = 10
# In seconds, how often to check for expired queued transfers
#QueueTimeoutCheckInterval = 300
# In seconds, how often to check for stalled transfers
#ActiveTimeoutCheckInterval = 300
# In seconds, how often to schedule new transfers
#SchedulingInterval = 2
# In seconds, how often to check for messages. Should be less than CheckStalledTimeout/2
#MessagingConsumeInterval = 1
#Enable or disable auto session reuse
AutoSessionReuse = true
#Max small file size for session reuse in bytes
AutoSessionReuseMaxSmallFileSize = 104857600
#Max big file size for session reuse in bytes
AutoSessionReuseMaxBigFileSize = 1073741824
#Max number of files per session reuse
AutoSessionReuseMaxFiles = 1000
#Max number of big files  per session reuse
AutoSessionReuseMaxBigFiles = 2
BackupTables=false
OptimizerMaxSuccessRate=100
OptimizerMedSuccessRate=80
OptimizerLowSuccessRate=75
OptimizerBaseSuccessRate=74
Port=8443
UseFixedJobPriority=0

ValidateAccessTokenOffline=True
JWKCacheSeconds=86400
TokenRefreshDaemonIntervalInSeconds=600
# Logging configuration
[loggers]
keys = root, routes, fts3rest, sqlalchemy

[handlers]
keys = console, log_file

[formatters]
keys = generic

[logger_root]
level = INFO
handlers = log_file

[logger_routes]
level = INFO
handlers =
qualname = routes.middleware
# "level = DEBUG" logs the route matched and routing variables.

[logger_fts3rest]
level = INFO
handlers =
qualname = fts3rest

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine
# "level = INFO" logs SQL queries.
# "level = DEBUG" logs SQL queries and results.
# "level = WARN" logs neither.  (Recommended for production systems.)

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[handler_log_file]
# See
# http://docs.python.org/2/library/logging.handlers.html
class = logging.FileHandler
args = ('/var/log/fts3rest/fts3rest.log', 'a')
level = NOTSET
formatter = generic

[formatter_generic]
format = %(asctime)s,%(msecs)03d %(levelname)-5.5s [%(module)s] %(message)s
datefmt = %H:%M:%S



[roles]
Public = all:transfer
lcgadmin = vo:transfer;vo:config
production = all:config

[providers]
xdc=https://iam.extreme-datacloud.eu
xdc_ClientId=
xdc_ClientSecret=
